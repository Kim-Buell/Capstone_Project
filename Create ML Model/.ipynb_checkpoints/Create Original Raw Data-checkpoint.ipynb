{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f01af81",
   "metadata": {},
   "source": [
    "## Create nhl_master_data Database in PostgreSQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42fc6f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import re\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "import time\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "830f6bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to PostgreSQL server\n",
    "conn = psycopg2.connect(\n",
    "    dbname=\"postgres\",       # Connect to the default PostgreSQL database\n",
    "    user=\"User_1\",           # Replace with your username\n",
    "    password=\"postgres\",     # Replace with your password\n",
    "    host=\"ip_address\",    # Replace with IP Address\n",
    "    port=\"5432\"              # Replace with your port\n",
    ")\n",
    "\n",
    "# Set autocommit to True\n",
    "conn.autocommit = True\n",
    "\n",
    "# Create a cursor object\n",
    "cur = conn.cursor()\n",
    "\n",
    "# Execute the query to create the database\n",
    "cur.execute(\"CREATE DATABASE nhl_master_data\")\n",
    "\n",
    "# Close the cursor\n",
    "cur.close()\n",
    "\n",
    "# Close the connection\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd0ad63e",
   "metadata": {},
   "source": [
    "## Create Original Raw Data Table in PostgreSQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a77f098",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_season_data(season_year, gameType=\"2\"):\n",
    "    \"\"\"Scrape NHL season data and store as DataFrames\"\"\"\n",
    "    # Note: gameType = 2 is Regular Season and gameType = 3 is Playoffs\n",
    "    # Set up Chrome WebDriver with headless option\n",
    "    chrome_options = Options()\n",
    "    chrome_options.add_argument(\"--headless\")\n",
    "    driver = webdriver.Chrome(options=chrome_options)\n",
    "\n",
    "    # Define the season and page variables\n",
    "    season = season_year\n",
    "\n",
    "    # Construct the URL using the season and page variables\n",
    "    url = f\"https://www.nhl.com/stats/teams?aggregate=0&reportType=game&seasonFrom={season}&seasonTo={season}&dateFromSeason&gameType={gameType}&sort=a_gameDate&page=0&pageSize=100\"\n",
    "\n",
    "    # Open the webpage\n",
    "    driver.get(url)\n",
    "\n",
    "    # Scroll to the bottom of the page\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "\n",
    "    # Wait for a brief moment to allow content to load\n",
    "    time.sleep(5)\n",
    "\n",
    "    # Retrieve the HTML content after the page has fully loaded\n",
    "    html_content = driver.page_source\n",
    "\n",
    "    # Close the browser\n",
    "    driver.quit()\n",
    "\n",
    "    # Use regular expression to find the max value\n",
    "    max_value_match = re.search(r'max=\"(\\d+)\"', html_content)\n",
    "\n",
    "    if max_value_match:\n",
    "        num_pages = max_value_match.group(1)\n",
    "    else:\n",
    "        print(\"Max value not found in the HTML.\")\n",
    "\n",
    "    # Set up Chrome WebDriver with headless option again for scraping data\n",
    "    chrome_options = Options()\n",
    "    chrome_options.add_argument(\"--headless\")\n",
    "    driver = webdriver.Chrome(options=chrome_options)\n",
    "\n",
    "    data = []  # Initialize an empty list to store data\n",
    "\n",
    "    # Loop through each page\n",
    "    for page in range(int(num_pages)):\n",
    "        # Construct the URL using the season and page variables\n",
    "        url = f\"https://www.nhl.com/stats/teams?aggregate=0&reportType=game&seasonFrom={season}&seasonTo={season}&dateFromSeason&gameType={gameType}&sort=a_gameDate&page={page}&pageSize=100\"\n",
    "\n",
    "        # Open the webpage\n",
    "        driver.get(url)\n",
    "\n",
    "        # Scroll to the bottom of the page\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "\n",
    "        # Wait for a brief moment to allow content to load\n",
    "        time.sleep(5)\n",
    "\n",
    "        # Retrieve the HTML content after the page has fully loaded\n",
    "        html_content = driver.page_source\n",
    "\n",
    "        # Create a BeautifulSoup object\n",
    "        soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "        # Extracting relevant data\n",
    "        rows = soup.find_all('div', class_='rt-tr-group')\n",
    "\n",
    "        # Append data based on game type\n",
    "        for row in rows:\n",
    "            columns = row.find_all('div', class_='rt-td')\n",
    "            team_name = columns[1].text.strip()\n",
    "            game_date = columns[2].text.strip()\n",
    "            GP = columns[3].text.strip()\n",
    "            W = columns[4].text.strip()\n",
    "            L = columns[5].text.strip()\n",
    "            T = columns[6].text.strip()\n",
    "\n",
    "            if gameType == \"2\" or season_year in [\"20192020\", \"20202021\"]:\n",
    "                OT = columns[7].text.strip()\n",
    "                P = columns[8].text.strip()\n",
    "                P_percent = columns[9].text.strip()\n",
    "                RW = columns[10].text.strip()\n",
    "                ROW = columns[11].text.strip()\n",
    "                SO_win = columns[12].text.strip()\n",
    "                GF = columns[13].text.strip()\n",
    "                GA = columns[14].text.strip()\n",
    "                GF_GP = columns[15].text.strip()\n",
    "                GA_GP = columns[16].text.strip()\n",
    "                PP_percent = columns[17].text.strip()\n",
    "                PK_percent = columns[18].text.strip()\n",
    "                Net_PP_percent = columns[19].text.strip()\n",
    "                Net_PK_percent = columns[20].text.strip()\n",
    "                Shots_GP = columns[21].text.strip()\n",
    "                SA_GP = columns[22].text.strip()\n",
    "                FOW_percent = columns[23].text.strip()\n",
    "\n",
    "                data.append({\n",
    "                    \"Team Name\": team_name,\n",
    "                    \"Game Date\": game_date,\n",
    "                    \"GP\": GP,\n",
    "                    \"W\": W,\n",
    "                    \"L\": L,\n",
    "                    \"T\": T,\n",
    "                    \"OT\": OT,\n",
    "                    \"P\": P,\n",
    "                    \"P%\": P_percent,\n",
    "                    \"RW\": RW,\n",
    "                    \"ROW\": ROW,\n",
    "                    \"SO_win\": SO_win,\n",
    "                    \"GF\": GF,\n",
    "                    \"GA\": GA,\n",
    "                    \"GF/GP\": GF_GP,\n",
    "                    \"GA/GP\": GA_GP,\n",
    "                    \"PP%\": PP_percent,\n",
    "                    \"PK%\": PK_percent,\n",
    "                    \"Net PP%\": Net_PP_percent,\n",
    "                    \"Net PK%\": Net_PK_percent,\n",
    "                    \"Shots/GP\": Shots_GP,\n",
    "                    \"SA/GP\": SA_GP,\n",
    "                    \"FOW%\": FOW_percent\n",
    "                })\n",
    "\n",
    "            elif gameType == \"3\":\n",
    "                P = columns[7].text.strip()\n",
    "                P_percent = columns[8].text.strip()\n",
    "                RW = columns[9].text.strip()\n",
    "                ROW = columns[10].text.strip()\n",
    "                SO_win = columns[11].text.strip()\n",
    "                GF = columns[12].text.strip()\n",
    "                GA = columns[13].text.strip()\n",
    "                GF_GP = columns[14].text.strip()\n",
    "                GA_GP = columns[15].text.strip()\n",
    "                PP_percent = columns[16].text.strip()\n",
    "                PK_percent = columns[17].text.strip()\n",
    "                Net_PP_percent = columns[18].text.strip()\n",
    "                Net_PK_percent = columns[19].text.strip()\n",
    "                Shots_GP = columns[20].text.strip()\n",
    "                SA_GP = columns[21].text.strip()\n",
    "                FOW_percent = columns[22].text.strip()\n",
    "\n",
    "                data.append({\n",
    "                    \"Team Name\": team_name,\n",
    "                    \"Game Date\": game_date,\n",
    "                    \"GP\": GP,\n",
    "                    \"W\": W,\n",
    "                    \"L\": L,\n",
    "                    \"T\": T,\n",
    "                    \"P\": P,\n",
    "                    \"P%\": P_percent,\n",
    "                    \"RW\": RW,\n",
    "                    \"ROW\": ROW,\n",
    "                    \"SO_win\": SO_win,\n",
    "                    \"GF\": GF,\n",
    "                    \"GA\": GA,\n",
    "                    \"GF/GP\": GF_GP,\n",
    "                    \"GA/GP\": GA_GP,\n",
    "                    \"PP%\": PP_percent,\n",
    "                    \"PK%\": PK_percent,\n",
    "                    \"Net PP%\": Net_PP_percent,\n",
    "                    \"Net PK%\": Net_PK_percent,\n",
    "                    \"Shots/GP\": Shots_GP,\n",
    "                    \"SA/GP\": SA_GP,\n",
    "                    \"FOW%\": FOW_percent\n",
    "                })\n",
    "\n",
    "    # Convert the list of dictionaries into a DataFrame\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    # Close the browser\n",
    "    driver.quit()\n",
    "\n",
    "    # Return the DataFrame\n",
    "    return df\n",
    "\n",
    "# Dictionary to store DataFrames\n",
    "season_data_dict = {}\n",
    "\n",
    "# Scrape and store data for each year and game type\n",
    "for year in [\"20182019\", \"20192020\", \"20202021\", \"20212022\", \"20222023\"]:\n",
    "    for game_Type in [\"2\",\"3\"]:\n",
    "        # Generate key for the dictionary\n",
    "        key = f\"{year} {'Regular Season' if game_Type == '2' else 'Playoff Season'}\"\n",
    "        # Store DataFrame in the dictionary\n",
    "        season_data_dict[key] = find_season_data(year, game_Type)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "641fd6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to add season and type columns to a DataFrame\n",
    "def add_season_and_type(df, season_year, gameType):\n",
    "    df['Season'] = season_year\n",
    "    df['Type'] = 'Regular Season' if gameType == \"2\" else 'Playoff'\n",
    "    return df\n",
    "\n",
    "# Initialize an empty list to store DataFrames\n",
    "dfs = []\n",
    "\n",
    "# Loop through the dataframes in the dictionary\n",
    "for key, df in season_data_dict.items():\n",
    "    # Check if \"OT\" column already exists\n",
    "    if \"OT\" not in df.columns:\n",
    "        # Add \"OT\" column with all values set to \"N/A\"\n",
    "        df.insert(df.columns.get_loc('P'), 'OT', 'N/A') \n",
    "\n",
    "    # Extract season year and game type from the key\n",
    "    season_year, gameType = key.split()[0], \"2\" if \"Regular\" in key else \"3\"\n",
    "\n",
    "    # Add season and type columns to the DataFrame\n",
    "    df = add_season_and_type(df, season_year, gameType)\n",
    "\n",
    "    # Append the DataFrame to the list\n",
    "    dfs.append(df)\n",
    "\n",
    "# Concatenate all DataFrames into one\n",
    "combined_df = pd.concat(dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40eda721",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the database connection string\n",
    "db_string = \"postgresql://User_1:postgres@1ip_address:5432/nhl_master_data\" # Enter IP Address\n",
    "\n",
    "# Create SQLAlchemy engine\n",
    "engine = create_engine(db_string)\n",
    "\n",
    "# Save the combined DataFrame as a table in PostgreSQL database\n",
    "combined_df.to_sql(\"original_raw_data\", engine, index=False, if_exists=\"replace\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
